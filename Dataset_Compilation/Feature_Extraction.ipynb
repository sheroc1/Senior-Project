{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5847868-a079-40d1-8b6a-f837c5d43b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second data compilation file, reads in the initialSet csv file populated with PDB_IDs & UniProt_IDs and queries/calculates the following features:\n",
    "\n",
    "# \"Surface_area\", \"sequence_length\", \"num_of_helicies\", \"num_of_strand\",\n",
    "#    \"total_helix_length\", \"total_Strand_length\", \"percent_helix\", \"percent_strand\",\n",
    "#    \"longest_helix_length\", \"longest_strand_length\", \"Molecular_weight\", \"Hydrophobicity\",\n",
    "#    \"ec_numbers\", \"sequence\",\n",
    "#    \"Hydrophobic_AA_percent\", \"Polar_AA_percent\", \"Basic_AA_percent\",\n",
    "#    \"Acidic_AA_percent\", \"Special_AA_percent\", \"Num_of_Chains\", \"SA_div_total_seq\"\n",
    "\n",
    "# It then appends them to the initialSet csv file - can pick up from where previous run left off (may take a few minutes to start back up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4742ba44-8cf2-4c1f-96a2-96955a434720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from Bio.PDB import PDBParser, PDBList\n",
    "from Bio.PDB.SASA import ShrakeRupley\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "# Define file paths\n",
    "input_file = \"/Users/carmenshero/Desktop/Datasets/initialSet.csv\"\n",
    "\n",
    "# Load dataset correctly (remove duplicate `pd.read_csv`)\n",
    "df_training = pd.read_csv(input_file, dtype={\"ec_numbers\": str, \"sequence\": str}, low_memory=False)\n",
    "\n",
    "# Define the exact column order for features (C to W)\n",
    "feature_columns = [\n",
    "    \"Surface_area\", \"sequence_length\", \"num_of_helicies\", \"num_of_strand\",\n",
    "    \"total_helix_length\", \"total_Strand_length\", \"percent_helix\", \"percent_strand\",\n",
    "    \"longest_helix_length\", \"longest_strand_length\", \"Molecular_weight\", \"Hydrophobicity\",\n",
    "    \"ec_numbers\", \"sequence\",\n",
    "    \"Hydrophobic_AA_percent\", \"Polar_AA_percent\", \"Basic_AA_percent\",\n",
    "    \"Acidic_AA_percent\", \"Special_AA_percent\", \"Num_of_Chains\", \"SA_div_total_seq\"\n",
    "]\n",
    "\n",
    "# Add missing columns with NaN\n",
    "for col in feature_columns:\n",
    "    if col not in df_training.columns:\n",
    "        df_training[col] = np.nan\n",
    "\n",
    "# Reorder columns to make sure PDB_ID, UniProt_ID come first, followed by feature columns\n",
    "column_order = [\"PDB_ID\", \"UniProt_ID\"] + feature_columns\n",
    "df_training = df_training[[col for col in column_order if col in df_training.columns]]\n",
    "\n",
    "# Replace \"nan\" and NaN with an empty string (ensures missing values are recognized)\n",
    "df_training[\"ec_numbers\"] = df_training[\"ec_numbers\"].replace([\"nan\", np.nan], \"\")\n",
    "df_training[\"sequence\"] = df_training[\"sequence\"].replace([\"nan\", np.nan], \"\")\n",
    "\n",
    "# Fix \"Processed\" logic to check only C-P but always reprocess empty sequences\n",
    "df_training[\"Processed\"] = df_training.iloc[:, 2:23].notnull().all(axis=1) & df_training[\"sequence\"].str.strip().astype(bool)\n",
    "\n",
    "# Identify rows that still need processing\n",
    "remaining_rows = df_training[~df_training[\"Processed\"]].copy()\n",
    "df_training.drop(columns=[\"Processed\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b0258c2-1a0b-4997-9334-c218a7c8583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch UniProt info\n",
    "def get_protein_info(uniprot_id):\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/{uniprot_id}.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "# Function to get protein sequence\n",
    "def get_protein_sequence(uniprot_id):\n",
    "    data = get_protein_info(uniprot_id)\n",
    "    if data:\n",
    "        return data.get('sequence', {}).get('value', 'N/A')\n",
    "    return 'N/A'\n",
    "\n",
    "# Function to get EC numbers\n",
    "def extract_ec_numbers(protein_info):\n",
    "    ec_numbers = []\n",
    "    if protein_info:\n",
    "        for comment in protein_info.get('comments', []):\n",
    "            if comment.get('commentType') == 'CATALYTIC ACTIVITY':\n",
    "                reaction = comment.get('reaction', {})\n",
    "                ec_number = reaction.get('ecNumber')\n",
    "                if ec_number:\n",
    "                    ec_numbers.append(ec_number)\n",
    "    return \";\".join(ec_numbers) if ec_numbers else \"MISSING\"\n",
    "\n",
    "# Function to get secondary structure info\n",
    "def get_pdbml(pdb_id):\n",
    "    url = f\"https://files.rcsb.org/view/{pdb_id}.xml\"\n",
    "    response = requests.get(url)\n",
    "    return response.content if response.status_code == 200 else None\n",
    "\n",
    "def parse_secondary_structure(pdbml_content):\n",
    "    if not pdbml_content:\n",
    "        return []\n",
    "    \n",
    "    root = ET.fromstring(pdbml_content)\n",
    "    ns = {'pdbx': 'http://pdbml.pdb.org/schema/pdbx-v50.xsd'}\n",
    "    sec_struct = []\n",
    "\n",
    "    for ss in root.findall('.//pdbx:struct_conf', ns):\n",
    "        start_res = ss.find('pdbx:beg_auth_seq_id', ns).text\n",
    "        end_res = ss.find('pdbx:end_auth_seq_id', ns).text\n",
    "        conf_type = ss.find('pdbx:conf_type_id', ns).text\n",
    "        sec_struct.append((int(start_res), int(end_res), conf_type))\n",
    "    \n",
    "    for ss in root.findall('.//pdbx:struct_sheet_range', ns):\n",
    "        start_res = ss.find('pdbx:beg_auth_seq_id', ns).text\n",
    "        end_res = ss.find('pdbx:end_auth_seq_id', ns).text\n",
    "        sec_struct.append((int(start_res), int(end_res), 'STRAND'))\n",
    "    \n",
    "    return sec_struct\n",
    "\n",
    "# Calculate surface area\n",
    "def Get_SA(pdb_id):\n",
    "    url = f\"https://files.rcsb.org/download/{pdb_id}.pdb\"\n",
    "    file_path = f\"/Users/carmenshero/Desktop/{pdb_id}.pdb\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return np.nan\n",
    "\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(pdb_id, file_path)\n",
    "    sr = ShrakeRupley()\n",
    "    sr.compute(structure, level=\"S\")\n",
    "    surface_area = structure.sasa\n",
    "\n",
    "    os.remove(file_path)  # Cleanup\n",
    "    return int(surface_area)\n",
    "\n",
    "# Define Amino Acid Groups\n",
    "aa_groups = {\n",
    "    'Hydrophobic': ['A', 'V', 'I', 'L', 'M', 'F', 'W', 'Y'],\n",
    "    'Polar': ['S', 'T', 'N', 'Q', 'C'],\n",
    "    'Basic': ['K', 'R', 'H'],\n",
    "    'Acidic': ['D', 'E'],\n",
    "    'Special': ['G', 'P']\n",
    "   # 'Other': ['X', 'U', 'B', 'Z']\n",
    "}\n",
    "\n",
    "# Function to Calculate Amino Acid Composition\n",
    "from itertools import chain\n",
    "\n",
    "def amino_acid_composition(sequence):\n",
    "    if sequence == \"N/A\" or sequence == \"\":\n",
    "        return {aa: 0.0 for aa in chain.from_iterable(aa_groups.values())}\n",
    "\n",
    "    # Include all amino acids from all groups, including 'Other'\n",
    "    amino_acid_counts = {aa: 0 for aa in chain.from_iterable(aa_groups.values())}\n",
    "\n",
    "    for amino_acid in sequence:\n",
    "        if amino_acid in amino_acid_counts:\n",
    "            amino_acid_counts[amino_acid] += 1\n",
    "        else:\n",
    "            # Optional: warn about truly unknown characters\n",
    "            print(f\"Unknown amino acid '{amino_acid}' skipped.\")\n",
    "\n",
    "    sequence_length = len(sequence)\n",
    "    if sequence_length == 0:\n",
    "        return {aa: 0.0 for aa in amino_acid_counts}\n",
    "\n",
    "    return {aa: (count / sequence_length) * 100 for aa, count in amino_acid_counts.items()}\n",
    "\n",
    "# Function to Group Amino Acid Frequencies into Categories\n",
    "def group_aa_frequencies(aa_percent):\n",
    "    grouped_data = {group: 0 for group in aa_groups.keys()}\n",
    "    for aa, freq in aa_percent.items():\n",
    "        for group, aas in aa_groups.items():\n",
    "            if aa in aas:\n",
    "                grouped_data[group] += freq\n",
    "                break\n",
    "    return grouped_data\n",
    "\n",
    "# Calculate molecular weight and hydrophobicity\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "import re\n",
    "\n",
    "# Calculate molecular weight and hydrophobicity\n",
    "def calculate_physicochemical_properties(sequence):\n",
    "    if sequence == \"N/A\":\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    analysed_seq = ProteinAnalysis(sequence)\n",
    "    return analysed_seq.molecular_weight(), analysed_seq.gravy()\n",
    "\n",
    "# Calculate number of chains (also needed for SA_div_total_seq)\n",
    "def get_num_of_chains(pdb_id):\n",
    "    \"\"\"Retrieve the number of chains from a PDB file.\"\"\"\n",
    "    pdbl = PDBList()\n",
    "    pdb_file = pdbl.retrieve_pdb_file(pdb_id, file_format='pdb')\n",
    "    \n",
    "    # Parse the PDB file\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(pdb_id, pdb_file)\n",
    "    \n",
    "    # Count unique chain IDs\n",
    "    num_chains = len(set(chain.id for model in structure for chain in model))\n",
    "    \n",
    "    # Clean up: Delete PDB file after use\n",
    "    os.remove(pdb_file)\n",
    "\n",
    "    return num_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31721cf6-e5c1-43f7-b9fc-df5a3e0b6ac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading PDB structure '1a1t'...\n",
      "✔ Updated 1A1T (Q75677) and saved progress.\n",
      "Downloading PDB structure '1a40'...\n",
      "✔ Updated 1A40 (P0AG82) and saved progress.\n",
      "Downloading PDB structure '1a45'...\n",
      "✔ Updated 1A45 (P23005) and saved progress.\n",
      "Downloading PDB structure '1a5p'...\n",
      "✔ Updated 1A5P (P61823) and saved progress.\n",
      "Downloading PDB structure '1a73'...\n",
      "✔ Updated 1A73 (Q94702) and saved progress.\n",
      "Downloading PDB structure '1a77'...\n",
      "✔ Updated 1A77 (Q58839) and saved progress.\n",
      "Downloading PDB structure '1a7b'...\n",
      "✔ Updated 1A7B (P08921) and saved progress.\n",
      "Downloading PDB structure '1a87'...\n",
      "✔ Updated 1A87 (P08083) and saved progress.\n",
      "Downloading PDB structure '1a8q'...\n",
      "✔ Updated 1A8Q (P33912) and saved progress.\n",
      "Downloading PDB structure '1a9t'...\n",
      "✔ Updated 1A9T (P55859) and saved progress.\n",
      "Downloading PDB structure '1a9v'...\n",
      "✔ Updated 1A9V (P49278) and saved progress.\n",
      "Downloading PDB structure '1acd'...\n",
      "✔ Updated 1ACD (P04117) and saved progress.\n",
      "Downloading PDB structure '1acw'...\n",
      "✔ Updated 1ACW (P56215) and saved progress.\n",
      "Downloading PDB structure '1ad7'...\n",
      "✔ Updated 1AD7 (P07231) and saved progress.\n"
     ]
    }
   ],
   "source": [
    "# Process each row\n",
    "for index, row in remaining_rows.iterrows():\n",
    "    pdb_id, uniprot_id = row[\"PDB_ID\"], row[\"UniProt_ID\"]\n",
    "\n",
    "    # Skip rows with missing UniProt ID\n",
    "    if not uniprot_id or pd.isna(uniprot_id):\n",
    "        print(f\"Skipping {pdb_id} due to missing UniProt ID.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Fetch data\n",
    "        protein_info = get_protein_info(uniprot_id)\n",
    "        sequence = get_protein_sequence(uniprot_id)\n",
    "        secondary_structure = parse_secondary_structure(get_pdbml(pdb_id))\n",
    "        surface_area = Get_SA(pdb_id)\n",
    "        num_of_chains = get_num_of_chains(pdb_id)\n",
    "\n",
    "        # Calculate Amino Acid Composition\n",
    "        aa_percent = amino_acid_composition(sequence)\n",
    "        grouped_frequencies = group_aa_frequencies(aa_percent)\n",
    "\n",
    "        # Calculate structural properties\n",
    "        total_helix_length = sum(end - start + 1 for start, end, conf in secondary_structure if \"HELX\" in conf)\n",
    "        total_strand_length = sum(end - start + 1 for start, end, conf in secondary_structure if conf == \"STRAND\")\n",
    "        sequence_length = len(sequence) if sequence != \"N/A\" else np.nan\n",
    "        percent_helix = round((total_helix_length / sequence_length) * 100, 2) if sequence_length else np.nan\n",
    "        percent_strand = round((total_strand_length / sequence_length) * 100, 2) if sequence_length else np.nan\n",
    "        longest_helix_length = max((end - start + 1 for start, end, conf in secondary_structure if \"HELX\" in conf), default=0)\n",
    "        longest_strand_length = max((end - start + 1 for start, end, conf in secondary_structure if conf == \"STRAND\"), default=0)\n",
    "        molecular_weight, hydrophobicity = calculate_physicochemical_properties(sequence)\n",
    "\n",
    "        # Calculate SA_div_total_seq\n",
    "        if num_of_chains > 0 and sequence_length > 0:  # Avoid division by zero\n",
    "            SA_div_total_seq = surface_area / (sequence_length / num_of_chains)\n",
    "        else:\n",
    "            SA_div_total_seq = np.nan  # Assign NaN if division is invalid\n",
    "\n",
    "        # Store updated values in the dataframe\n",
    "        df_training.at[index, \"Surface_area\"] = surface_area\n",
    "        df_training.at[index, \"sequence_length\"] = sequence_length\n",
    "        df_training.at[index, \"num_of_helicies\"] = sum(1 for _, _, conf in secondary_structure if \"HELX\" in conf)\n",
    "        df_training.at[index, \"num_of_strand\"] = sum(1 for _, _, conf in secondary_structure if conf == \"STRAND\")\n",
    "        df_training.at[index, \"total_helix_length\"] = total_helix_length\n",
    "        df_training.at[index, \"total_Strand_length\"] = total_strand_length\n",
    "        df_training.at[index, \"percent_helix\"] = percent_helix\n",
    "        df_training.at[index, \"percent_strand\"] = percent_strand\n",
    "        df_training.at[index, \"longest_helix_length\"] = longest_helix_length\n",
    "        df_training.at[index, \"longest_strand_length\"] = longest_strand_length\n",
    "        df_training.at[index, \"Molecular_weight\"] = molecular_weight\n",
    "        df_training.at[index, \"Hydrophobicity\"] = hydrophobicity\n",
    "        df_training.at[index, \"ec_numbers\"] = extract_ec_numbers(protein_info)  # Always returns a string\n",
    "        df_training.at[index, \"sequence\"] = sequence  # Store protein sequence\n",
    "        \n",
    "        # Assign Amino Acid Percentages (Columns Q-U)\n",
    "        df_training.at[index, \"Hydrophobic_AA_percent\"] = grouped_frequencies[\"Hydrophobic\"]\n",
    "        df_training.at[index, \"Polar_AA_percent\"] = grouped_frequencies[\"Polar\"]\n",
    "        df_training.at[index, \"Basic_AA_percent\"] = grouped_frequencies[\"Basic\"]\n",
    "        df_training.at[index, \"Acidic_AA_percent\"] = grouped_frequencies[\"Acidic\"]\n",
    "        df_training.at[index, \"Special_AA_percent\"] = grouped_frequencies[\"Special\"]\n",
    "        df_training.at[index, \"Num_of_Chains\"] = num_of_chains\n",
    "        df_training.at[index, \"SA_div_total_seq\"] = SA_div_total_seq\n",
    "        \n",
    "        # Save progress after processing each row\n",
    "        df_training.to_csv(input_file, index=False)  \n",
    "        print(f\"✔ Updated {pdb_id} ({uniprot_id}) and saved progress.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdb_id} ({uniprot_id}): {e}\")\n",
    "        continue  # Skip this row and move to the next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9981300c-bafa-43b4-a8b6-cb916e163071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
