{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a8c477-7697-4be6-ac69-891387c1ce9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Cleaned dataset loaded with shape: (12954, 33)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load data\n",
    "file_path = \"/Users/carmenshero/Desktop/Datasets2/PT4_Training.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove missing ec_numbers\n",
    "df = df[df[\"ec_numbers\"].notna() & (df[\"ec_numbers\"] != \"MISSING\")].copy()\n",
    "\n",
    "# Extract EC prefix and store in new column\n",
    "df[\"EC_Prefix\"] = df[\"ec_numbers\"].str.extract(r\"^(\\d+\\.\\d+)\")\n",
    "\n",
    "# Remove EC_Prefixes with fewer than 2 entries\n",
    "prefix_counts = df[\"EC_Prefix\"].value_counts()\n",
    "valid_prefixes = prefix_counts[prefix_counts >= 2].index\n",
    "df = df[df[\"EC_Prefix\"].isin(valid_prefixes)].reset_index(drop=True)\n",
    "\n",
    "print(\"✔ Cleaned dataset loaded with shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a79995d8-9523-41d0-864a-010b489256c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Features and labels prepared.\n",
      "🔢 Number of classes: 61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_combined = df.iloc[:, 3:33]\n",
    "\n",
    "# Re-encode filtered EC prefixes into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df[\"EC_Prefix\"])\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "print(\"✔ Features and labels prepared.\")\n",
    "print(f\"Number of classes: {y_categorical.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81457199-5196-4036-85b0-0ba9646d870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Train-test split complete.\n",
      "📊 Training samples: 10363 | Test samples: 2591\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split while stratifying by encoded EC labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y_categorical, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(\"✔ Train-test split complete.\")\n",
    "print(f\"Training samples: {len(X_train)} | Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9db5660-6f52-4087-b1a3-ff08ab55a045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carmenshero/Desktop/DSCI350/VS-Code/ic01-python_intro/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0731 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 2/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0401 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 3/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0380 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 4/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0383 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 5/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0430 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 6/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0397 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 7/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0392 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 8/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0384 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 9/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0405 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 10/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0434 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 11/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0388 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 12/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0386 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 13/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0418 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 14/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0370 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 15/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0398 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 16/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0389 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 17/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0395 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 18/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0391 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 19/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0386 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 20/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.0407 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 21/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0395 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 22/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0391 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 23/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0369 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 24/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0391 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 25/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0343 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 26/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0398 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 27/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0416 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 28/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0415 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 29/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0363 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 30/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0400 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 31/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0382 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 32/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0379 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 33/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0397 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 34/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0404 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 35/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0386 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 36/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0405 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 37/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0413 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 38/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0412 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 39/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0385 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 40/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0453 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 41/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0385 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 42/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0414 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 43/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0386 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 44/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.0381 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 45/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0387 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 46/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0397 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 47/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0397 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 48/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0350 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 49/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0412 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "Epoch 50/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0440 - loss: nan - val_accuracy: 0.0357 - val_loss: nan\n",
      "✅ Training complete with increased capacity.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(512, activation=\"relu\", input_shape=(X_combined.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(y_categorical.shape[1], activation=\"softmax\")  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "print(\"Training complete with increased capacity.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083b2ef-5c33-4d8b-9b6e-8c75695f7f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the held-out test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e13293-ce8b-4cbd-9776-c95a8f316d7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError
     ]
    }
   ],
   "source": [
    "# Load the full dataset again\n",
    "full_df = pd.read_csv(\"/Users/carmenshero/Desktop/Datasets/Partial_Testing.csv\")\n",
    "\n",
    "# Extract MISSING rows\n",
    "df_missing = full_df[full_df[\"ec_numbers\"] == \"MISSING\"].copy()\n",
    "\n",
    "# Get features for prediction (must match training input)\n",
    "X_missing = df_missing.iloc[:, 5:28]\n",
    "\n",
    "# Predict probabilities and convert to EC number predictions\n",
    "y_missing_pred = model.predict(X_missing)\n",
    "y_pred_labels = label_encoder.inverse_transform(np.argmax(y_missing_pred, axis=1))\n",
    "\n",
    "# Store results\n",
    "df_missing[\"Predicted_EC\"] = y_pred_labels\n",
    "\n",
    "# Save predictions\n",
    "df_missing.to_csv(\"/Users/carmenshero/Desktop/Datasets/NN_EC_Predictions.csv\", index=False)\n",
    "print(\" Saved predicted EC values for MISSING rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c2961a-ab6e-487b-9361-9fb149997eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
